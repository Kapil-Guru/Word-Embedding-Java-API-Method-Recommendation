{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEnter the statement 1:\u001b[0m\n",
      "How to kill a thread in Java?\n",
      "Statement 1 after Tokenization:\n",
      "\u001b[31m['how', 'to', 'kill', 'a', 'thread', 'in', 'java', '?']\u001b[0m\n",
      "Statement 1 after Stemming:\n",
      "\u001b[34m['how', 'to', 'kill', 'a', 'thread', 'in', 'java', '?']\u001b[0m\n",
      "-------------------------------------------\n",
      "\u001b[32mEnter the statement 2:\u001b[0m\n",
      "How to create a thread in java?\n",
      "Statement 2 after Tokenization:\n",
      "\u001b[31m['how', 'to', 'create', 'a', 'thread', 'in', 'java', '?']\u001b[0m\n",
      "Statement 2 after Stemming:\n",
      "\u001b[34m['how', 'to', 'creat', 'a', 'thread', 'in', 'java', '?']\u001b[0m\n",
      "The idf value for word: \u001b[31mhow\u001b[0m  :  \u001b[32m2.533656505487701\u001b[0m\n",
      "The idf value for word: \u001b[31mto\u001b[0m  :  \u001b[32m0.36778105765469626\u001b[0m\n",
      "The idf value for word: \u001b[31mkill\u001b[0m  :  \u001b[32m5.899771285960787\u001b[0m\n",
      "The idf value for word: \u001b[31ma\u001b[0m  :  \u001b[32m0.5755543669665788\u001b[0m\n",
      "The idf value for word: \u001b[31mthread\u001b[0m  :  \u001b[32m2.8785584251228173\u001b[0m\n",
      "The idf value for word: \u001b[31min\u001b[0m  :  \u001b[32m0.6800034209749307\u001b[0m\n",
      "The idf value for word: \u001b[31mjava\u001b[0m  :  \u001b[32m1.7135938501242525\u001b[0m\n",
      "The idf value for word: \u001b[31m?\u001b[0m  :  \u001b[32m2.446430788020151\u001b[0m\n",
      "The idf value for word: \u001b[31mhow\u001b[0m  :  \u001b[32m2.533656505487701\u001b[0m\n",
      "The idf value for word: \u001b[31mto\u001b[0m  :  \u001b[32m0.36778105765469626\u001b[0m\n",
      "The idf value for word: \u001b[31mcreat\u001b[0m  :  \u001b[32m2.012056633255468\u001b[0m\n",
      "The idf value for word: \u001b[31ma\u001b[0m  :  \u001b[32m0.5755543669665788\u001b[0m\n",
      "The idf value for word: \u001b[31mthread\u001b[0m  :  \u001b[32m2.8785584251228173\u001b[0m\n",
      "The idf value for word: \u001b[31min\u001b[0m  :  \u001b[32m0.6800034209749307\u001b[0m\n",
      "The idf value for word: \u001b[31mjava\u001b[0m  :  \u001b[32m1.7135938501242525\u001b[0m\n",
      "The idf value for word: \u001b[31m?\u001b[0m  :  \u001b[32m2.446430788020151\u001b[0m\n",
      "\n",
      "\n",
      "The similarity Score between the statements: \n",
      "\u001b[31mHow to kill a thread in Java?\u001b[0m  &&  \u001b[34mHow to create a thread in java?\u001b[0m  is:  0.8300032844248236\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import gensim\n",
    "import _pickle as pickle\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from termcolor import colored\n",
    "\n",
    "\n",
    "def init_doc_matrix(doc,w2v):\n",
    "\n",
    "    matrix = np.zeros((len(doc),100)) #word embedding size is 100\n",
    "    #print(\"----Converting words to Vectors\")\n",
    "    for i, word in enumerate(doc):\n",
    "        if word in w2v.wv.key_to_index:\n",
    "            matrix[i] = np.array(w2v.wv[word])\n",
    "            #print(\"Vector representation of: \",word,\":\",colored(matrix[i],\"green\"))\n",
    "\n",
    "    #l2 normalize\n",
    "    try:\n",
    "        norm = np.linalg.norm(matrix, axis=1).reshape(len(doc), 1)\n",
    "        matrix = np.divide(matrix, norm, out=np.zeros_like(matrix), where=norm!=0)\n",
    "        #matrix = matrix / np.linalg.norm(matrix, axis=1).reshape(len(doc), 1)\n",
    "    except RuntimeWarning:\n",
    "        print (doc)\n",
    "\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def init_doc_idf_vector(doc,idf):\n",
    "    idf_vector = np.zeros((1,len(doc)))  # word embedding size is 100\n",
    "    for i, word in enumerate(doc):\n",
    "        if word in idf:\n",
    "            idf_vector[0][i] = idf[word][1]\n",
    "            print(\"The idf value for word:\",colored(word,\"red\"),\" : \",colored(idf_vector[0][i],\"green\"))\n",
    "\n",
    "    return idf_vector\n",
    "\n",
    "\n",
    "\n",
    "def sim_doc_pair(matrix1,matrix2,idf1,idf2):\n",
    "\n",
    "    sim12 = (idf1*(matrix1.dot(matrix2.T).max(axis=1))).sum() / idf1.sum()\n",
    "\n",
    "    sim21 = (idf2*(matrix2.dot(matrix1.T).max(axis=1))).sum() / idf2.sum()\n",
    "\n",
    "\n",
    "    return 2 * sim12 * sim21 / (sim12 + sim21)\n",
    "    total_len = matrix1.shape[0] + matrix2.shape[0]\n",
    "    return sim12 * matrix2.shape[0] / total_len + sim21 * matrix1.shape[0] / total_len\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    w2v = gensim.models.Word2Vec.load('../data/w2v_model_stemmed')\n",
    "    idf = pickle.load(open('../data/idf','rb'))\n",
    "\n",
    "\n",
    "    print(colored(\"Enter the statement 1:\",\"green\"))\n",
    "    question1 = input()\n",
    "    text1=question1\n",
    "    question1 = WordPunctTokenizer().tokenize(question1.lower())\n",
    "    print(\"Statement 1 after Tokenization:\")\n",
    "    print(colored(question1,\"red\"))\n",
    "    question1 = [SnowballStemmer('english').stem(word) for word in question1]\n",
    "    print(\"Statement 1 after Stemming:\")\n",
    "    print(colored(question1,\"blue\"))\n",
    "    \n",
    "    print(\"-------------------------------------------\")\n",
    "    \n",
    "    print(colored(\"Enter the statement 2:\",\"green\"))\n",
    "    question2 = input()\n",
    "    text2=question2\n",
    "    question2 = WordPunctTokenizer().tokenize(question2.lower())\n",
    "    print(\"Statement 2 after Tokenization:\")\n",
    "    print(colored(question2,\"red\"))\n",
    "    question2 = [SnowballStemmer('english').stem(word) for word in question2]\n",
    "    print(\"Statement 2 after Stemming:\")\n",
    "    print(colored(question2,\"blue\"))\n",
    "\n",
    "    matrix1 = init_doc_matrix(question1,w2v)\n",
    "    matrix2 = init_doc_matrix(question2,w2v)\n",
    "    #print(matrix1)\n",
    "    matrix1_trans = matrix1.T\n",
    "    matrix2_trans = matrix2.T\n",
    "\n",
    "    idf1 = init_doc_idf_vector(question1,idf)\n",
    "    idf2 = init_doc_idf_vector(question2,idf)\n",
    "    print(\"\\n\\nThe similarity Score between the statements: \")\n",
    "    print(colored(text1,\"red\"),\" && \" ,colored(text2,\"blue\"),\" is: \",sim_doc_pair(matrix1, matrix2, idf1, idf2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
